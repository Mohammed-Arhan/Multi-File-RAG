{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain cohere langchain_community huggingface_hub streamlit cassio datasets tiktoken pypdf requests sentence-transformers uvicorn ctransformers unstructured pinecone-client pandas numpy langchain-pinecone pinecone[grpc] google-generativeai chromadb faiss-cpu spider-client firecrawl-py\n",
        "!pip install -q requests langchain langchain_community langchain_groq pypdf cohere pandas faiss-cpu pillow google-generativeai chromadb"
      ],
      "metadata": {
        "id": "FwgK-yz_ylXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyyNWtjEycv0"
      },
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import CohereEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.llms import Cohere\n",
        "from langchain.storage import LocalFileStore\n",
        "from langchain.embeddings import CacheBackedEmbeddings\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "import os\n",
        "from PIL import Image\n",
        "import google.generativeai as genai\n",
        "from langchain.document_loaders.csv_loader import CSVLoader\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "import sqlite3\n",
        "\n",
        "llm = Cohere()\n",
        "\n",
        "class Document:\n",
        "    def __init__(self, text, metadata=None):\n",
        "        self.page_content = text\n",
        "        self.metadata = metadata or {}\n",
        "\n",
        "def truncate_text(text, max_length):\n",
        "    return text[:max_length]\n",
        "\n",
        "def get_gemini_response_for_txt(input,txt,prompt):\n",
        "  response=model.generate_content([input,txt,prompt])\n",
        "  return response.text\n",
        "\n",
        "\n",
        "def text_rag(file_content, query):\n",
        "    # Truncate file content if too long\n",
        "    max_chunk_size = 4000  # Set a safe limit considering prompt + document\n",
        "    truncated_content = truncate_text(file_content, max_chunk_size)\n",
        "\n",
        "    documents = [Document(truncated_content)]\n",
        "    text_splitter = CharacterTextSplitter(chunk_size=800, chunk_overlap=200)\n",
        "    docs = text_splitter.split_documents(documents)\n",
        "    embeddings = CohereEmbeddings(user_agent=\"app\")\n",
        "\n",
        "    store = LocalFileStore(\"./cache/\")\n",
        "\n",
        "    cached_embedder = CacheBackedEmbeddings.from_bytes_store(\n",
        "        embeddings , store, namespace=embeddings.model\n",
        "    )\n",
        "\n",
        "    db = FAISS.from_documents(docs, cached_embedder)\n",
        "\n",
        "    template = ChatPromptTemplate.from_template(\"\"\"\n",
        "        You are a helpful assistant. You will be uploaded with a txt file in which some questions might be asked.\n",
        "        Answer the question based on the relevant documents. If the answer is not based on the relevant documents,\n",
        "        then just say i dont know or say what you know.\n",
        "    \"\"\")\n",
        "\n",
        "    # Ensure prompt length is within limits\n",
        "\n",
        "\n",
        "    relevant_docs=db.similarity_search(query)\n",
        "\n",
        "    relevant_docs_content = \" \".join([doc.page_content for doc in relevant_docs])\n",
        "\n",
        "    formatted_template=template.format(query=query)\n",
        "\n",
        "\n",
        "    res = get_gemini_response_for_txt(formatted_template,relevant_docs_content,query)\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "def get_gemini_response_for_pdf(input,pdf,prompt):\n",
        "  response=model.generate_content([input,pdf,prompt])\n",
        "  return response.text\n",
        "\n",
        "def pdf_reader(file_path, query):\n",
        "    loader = PyPDFLoader(file_path)\n",
        "    documents = loader.load()\n",
        "\n",
        "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    docs = text_splitter.split_documents(documents)\n",
        "\n",
        "    embeddings = CohereEmbeddings(user_agent=\"app\")\n",
        "    store = LocalFileStore(\"./cache/\")\n",
        "\n",
        "    cached_embedder = CacheBackedEmbeddings.from_bytes_store(\n",
        "        embeddings, store, namespace=embeddings.model\n",
        "    )\n",
        "\n",
        "    db = FAISS.from_documents(docs, cached_embedder)\n",
        "\n",
        "    template = ChatPromptTemplate.from_template(\"\"\"\n",
        "        You are a helpful assistant. You will be uploaded with a PDF file in which some questions might be asked.\n",
        "        Answer the question based on the relevant documents. If the answer is not based on the relevant documents,\n",
        "        then just say 'I don't know' or say what you know.\n",
        "    \"\"\")\n",
        "\n",
        "    relevant_docs=relevant_docs=db.similarity_search(query)\n",
        "\n",
        "    relevant_docs_content = \" \".join([doc.page_content for doc in relevant_docs])\n",
        "\n",
        "    formatted_template=template.format(query=query)\n",
        "    res = get_gemini_response_for_pdf(formatted_template,relevant_docs_content,query)\n",
        "    res = res.replace(\"\\\\n\", \"\\n\")\n",
        "    return res\n",
        "\n",
        "\n",
        "genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))\n",
        "\n",
        "#function to load gemini pro\n",
        "model=genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "def get_gemini_response_for_image(input,image,prompt):\n",
        "  response=model.generate_content([input,image[0],prompt])\n",
        "  return response.text\n",
        "\n",
        "\n",
        "def input_image_details(uploaded_file):\n",
        "  if uploaded_file is not None:\n",
        "    bytes_data=uploaded_file.getvalue()\n",
        "\n",
        "    image_parts=[\n",
        "        {\n",
        "            \"data\":bytes_data,\n",
        "            \"mime_type\":uploaded_file.type\n",
        "        }\n",
        "    ]\n",
        "    return image_parts\n",
        "  else:\n",
        "    return FileNotFoundError(\"File not found\")\n",
        "\n",
        "def get_gemini_response_for_csv(input,relevant_doc,prompt):\n",
        "  model=genai.GenerativeModel(\"gemini-pro\")\n",
        "  response=model.generate_content([input])\n",
        "  return response.text\n",
        "\n",
        "def csv_reader(file,query):\n",
        "  loader=CSVLoader(file_path=file)\n",
        "  documents=loader.load()\n",
        "\n",
        "  text_splitter=CharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
        "  docs=text_splitter.split_documents(documents)\n",
        "\n",
        "  embeddings=CohereEmbeddings(user_agent=\"app\")\n",
        "\n",
        "  store = LocalFileStore(\"./cache/\")\n",
        "\n",
        "  cached_embedder = CacheBackedEmbeddings.from_bytes_store(\n",
        "        embeddings, store, namespace=embeddings.model\n",
        "    )\n",
        "\n",
        "  db=FAISS.from_documents(docs,cached_embedder)\n",
        "  relevant_docs = db.similarity_search(query)\n",
        "\n",
        "    # Extract the content from the relevant documents\n",
        "  relevant_docs_content = \" \".join([doc.page_content for doc in relevant_docs])\n",
        "\n",
        "  prompt=ChatPromptTemplate.from_template(\"\"\"You are an expert CSV reader.\n",
        "   A human will upload a CSV, and you must answer based on it, accurately referencing rows and columns.\n",
        "   Keep the format clean with proper spaces and new lines. If unsure, just say what you know without making up answers.\n",
        "   Use exact data from the file without repeating or replacing it.\n",
        "   Be friendly, and in conversations, avoid checking the documents unless necessary\n",
        "   These are the relevant documents <content> {relevant_docs} <content> question: {query}\"\"\")\n",
        "\n",
        "  formatted_prompt = prompt.format(relevant_docs=relevant_docs_content, query=query)\n",
        "  #res=llm.invoke(prompt.format(relevant_docs=db.similarity_search(query),query=query)).replace(\"\\n\",' ')\n",
        "  res=get_gemini_response_for_csv(formatted_prompt,relevant_docs_content, query)\n",
        "\n",
        "  res = res.replace(\"\\\\n\", \"\\n\")\n",
        "\n",
        "  return res\n",
        "\n",
        "\n",
        "def get_gemini_response_for_link(input,link,prompt):\n",
        "  response=model.generate_content([input,link,prompt])\n",
        "  return response.text\n",
        "\n",
        "def link_reader(link,query):\n",
        "  loader = WebBaseLoader(link)\n",
        "\n",
        "  document = loader.load()\n",
        "  text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "  docs = text_splitter.split_documents(document)\n",
        "\n",
        "  embeddings = CohereEmbeddings(user_agent=\"app\")\n",
        "\n",
        "  store = LocalFileStore(\"./cache/\")\n",
        "\n",
        "  cached_embedder = CacheBackedEmbeddings.from_bytes_store(\n",
        "      embeddings, store, namespace=embeddings.model\n",
        "  )\n",
        "\n",
        "  db = FAISS.from_documents(docs, cached_embedder)\n",
        "\n",
        "  relevant_docs = db.similarity_search(query)\n",
        "\n",
        "  # Extract the content from the relevant documents\n",
        "  relevant_docs_content = \" \".join([doc.page_content for doc in relevant_docs])\n",
        "\n",
        "  prompt = ChatPromptTemplate.from_template(\n",
        "      \"\"\"You are an expert assistant. Based on the provided documents, answer the user's query in a clean and structured paragraph. Present the information in a readable way, using sentences and avoiding '\\n' or any line breaks.\n",
        "\n",
        "        If there are multiple points or items, list them in sentence form using commas or semi-colons to separate them.\n",
        "\n",
        "        Ensure the response is concise, factual, and based strictly on the documents provided. If the user asks a casual question (e.g., \"Hello\" or \"How are you?\"), respond in a friendly, conversational tone. Avoid adding irrelevant information and maintain accuracy from the relevant documents.\n",
        "        Related document: <content>related_docs_content<content> question: {query}\n",
        "        \"\"\"\n",
        "  )\n",
        "  formatted_prompt = prompt.format(relevant_docs=relevant_docs_content, query=query)\n",
        "  res = get_gemini_response_for_link(formatted_prompt,relevant_docs_content, query)\n",
        "\n",
        "  res = res.replace(\"\\\\n\", \"\\n\")\n",
        "\n",
        "  return res\n",
        "\n",
        "def get_gimini_response_for_db(query,prompt):\n",
        "  model=genai.GenerativeModel('gemini-pro')\n",
        "  response=model.generate_content([prompt[0], query])\n",
        "  return response.text\n",
        "\n",
        "def get_gimini_response_for_nice_db(prompt_2,query,res):\n",
        "  model=genai.GenerativeModel('gemini-pro')\n",
        "  response=model.generate_content([prompt_2, query,res])\n",
        "  return response.text\n",
        "\n",
        "def read_sql_query(query, db):\n",
        "  connection=sqlite3.connect(db)\n",
        "  cursor=connection.cursor()\n",
        "  cursor.execute(query)\n",
        "  result=cursor.fetchall()\n",
        "  connection.close()\n",
        "\n",
        "  for row in result:\n",
        "    print(row)\n",
        "\n",
        "  return row\n",
        "\n",
        "\n",
        "prompt_for_db=[\n",
        "    \"\"\"\n",
        "    You are an expert in converting English questions to SQL query!\n",
        "    The SQL database has the name STUDENT and has the following columns - NAME, CLASS,\n",
        "    SECTION AND MARKS\\n\\nFor example,\\nExample 1 - How many entries of records are present?,\n",
        "    the SQL command will be something like this SELECT COUNT(*) FROM STUDENT ;\n",
        "    \\nExample 2 - Tell me all the students studying in Data Science class?,\n",
        "    the SQL command will be something like this SELECT * FROM STUDENT\n",
        "    where CLASS=\"Data Science\";\n",
        "    also the sql code should not have ``` in beginning or end and sql word in output\n",
        "    Dont give any rubbish answers. Make sure the answer's are precise and correct.\n",
        "    \"\"\"\n",
        "]\n",
        "\n",
        "prompt_for_nice_db=\"\"\"\n",
        "You are an expert writer.\n",
        "Once, you had a brother who was an expert in English questions to SQL query.\n",
        "You got seperated by some consequences and now you meet each other after 10 years.\n",
        "Your brother tells that he only has the talent to give the direct answer but not in a sentence.\n",
        "That's why he asks you to help him make a sentence with the output that he is giving.\n",
        "Cherished that you have met him after 10 years you do it very affectively and properly.\n",
        "\n",
        "Also while answering dont state anything about your brother or your past just the answer.\n",
        "\n",
        "This is the query and the result, Make a sentence for the output.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "# Streamlit app\n",
        "st.set_page_config(page_title=\"CHATOOOO\")\n",
        "\n",
        "st.title(\"CHATOOOO\")\n",
        "\n",
        "# Track the selected file type\n",
        "if 'file_type' not in st.session_state:\n",
        "    st.session_state.file_type = None\n",
        "if 'query' not in st.session_state:\n",
        "    st.session_state.query = None\n",
        "\n",
        "file_type = st.selectbox(\"Choose file type to upload:\", ('Text', 'PDF', 'Image', 'CSV', 'LINK','DB', 'SQLITE'))\n",
        "\n",
        "# Reset query when file type changes\n",
        "if file_type != st.session_state.file_type:\n",
        "    st.session_state.file_type = file_type\n",
        "    st.session_state.query = None  # Clear the query\n",
        "\n",
        "uploaded_file = None\n",
        "link_input = None\n",
        "\n",
        "if file_type in ['Text', 'PDF', 'Image', 'CSV','DB' ,'SQLITE']:\n",
        "    uploaded_file = st.file_uploader(\"Upload a file\", type=['txt', 'pdf', 'jpg', 'png', 'jpeg', 'csv','db', 'sqlite'])\n",
        "elif file_type == 'LINK':\n",
        "    link_input = st.text_input(\"Enter the link:\")\n",
        "\n",
        "# Update query state\n",
        "query = st.text_input(\"Enter your query:\", key=\"query\")\n",
        "\n",
        "if st.session_state.query:\n",
        "    if file_type in ['Text', 'PDF', 'CSV','DB' ,'SQLITE']:\n",
        "        if uploaded_file:\n",
        "            file_name = f\"temp_{file_type.lower()}_file.txt\"\n",
        "            with open(file_name, \"wb\") as file:\n",
        "                file.write(uploaded_file.getbuffer())\n",
        "\n",
        "    if file_type == 'Text' and uploaded_file is not None:\n",
        "        st.write(\"Processing text file...\")\n",
        "        file_content = uploaded_file.read().decode(\"utf-8\")\n",
        "        result = text_rag(file_content, st.session_state.query)\n",
        "        st.subheader(\"Response: \")\n",
        "        st.write(result)\n",
        "\n",
        "    elif file_type == 'PDF':\n",
        "        st.write(\"Processing PDF file...\")\n",
        "        result = pdf_reader(file_name, st.session_state.query)\n",
        "        st.subheader(\"Response: \")\n",
        "        st.write(result)\n",
        "\n",
        "    elif file_type == 'Image':\n",
        "        input_prompt = \"You are an expert in telling what's in the image like the features and many more things in a very unique style. The human will upload and ask some questions based on the image and you have to answer those questions only based on the image uploaded.\"\n",
        "        image_data = input_image_details(uploaded_file)\n",
        "        response = get_gemini_response_for_image(input_prompt, image_data, st.session_state.query)\n",
        "        st.subheader(\"Response: \")\n",
        "        st.write(response)\n",
        "\n",
        "        if uploaded_file is not None:\n",
        "            image = Image.open(uploaded_file)\n",
        "            st.image(image, caption=\"Uploaded Image\", use_column_width=True)\n",
        "\n",
        "    elif file_type == 'CSV':\n",
        "        st.write(\"Processing CSV file...\")\n",
        "        result = csv_reader(file_name, st.session_state.query)\n",
        "        st.subheader(\"Response: \")\n",
        "        st.write(result)\n",
        "\n",
        "    elif file_type == 'LINK' and link_input:\n",
        "        st.write(f\"Processing link: {link_input}\")\n",
        "        result = link_reader(link_input, st.session_state.query)\n",
        "        st.subheader(\"Response: \")\n",
        "        st.write(result)\n",
        "\n",
        "    elif file_type == 'DB':\n",
        "        st.write(\"Processing DB/SQLITE file...\")\n",
        "        response=get_gimini_response_for_db(st.session_state.query,prompt_for_db)\n",
        "        data=read_sql_query(response,file_name)\n",
        "\n",
        "        st.subheader(\"Response\")\n",
        "\n",
        "        for row in data:\n",
        "          result_for_text=get_gimini_response_for_nice_db(prompt_for_nice_db,st.session_state.query,row)\n",
        "          st.write(result_for_text)\n",
        "\n",
        "    elif file_type == 'SQLITE':\n",
        "      st.write(\"Processing SQLITE file...\")\n",
        "      response=get_gimini_response_for_db(st.session_state.query,prompt_for_db)\n",
        "      data=read_sql_query(response,file_name)\n",
        "\n",
        "      st.subheader(\"Response\")\n",
        "\n",
        "      for row in data:\n",
        "        result_for_text=get_gimini_response_for_nice_db(prompt_for_nice_db,st.session_state.query,row)\n",
        "        st.write(result_for_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl icanhazip.com\n",
        "print()\n",
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "ViOfFlnKykEj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}